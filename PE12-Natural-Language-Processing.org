* <<<CP1224>>> NATURAL LANGUAGE PROCESSING
:Properties:
:author:  B Senthil Kumar, D Thenmozhi
:date: 11 May 2022
:end:

#+startup: showall

{{{credits}}}
|L|T|P|C|
|3|0|0|3|

** Course Objectives
- To learn the language models.
- To understand the levels of knowledge in language processing.
- To understand sequence processing of text. 
- To explore text processing using Python.

{{{unit}}}
|Unit I |Introduction|8| 
Origins and challenges of NLP -- Knowledge in language processing -- Ambiguity
-- NLP applications; Text Normalization -- N-grams -- Evaluation -- Sampling -- 
Generalization -- Smoothing


{{{unit}}}
|Unit II|Vector Semantics and Neural Language Modeling|9|
Vector Semantics: Words and vectors -- Cosine similarity -- TF-IDF -- PPMI -- Word2Vec -- Semantic properties 
of embeddings -- Evaluating vector model; Neural language model: Feedforward networks for NLP -- 
Feedforward Neural Language Modeling -- Training the neural language model -- RNN as Language Model


{{{unit}}}
|Unit III|Word Level and Syntactic Analysis |10| 
English Word Classes -- Part-of-Speech Tagging -- HMM PoS Tagging -- Context-free grammar -- 
Grammar rules for Engligh -- Treebanks -- Constituency Parsing: Ambiguity -- CKY Parsing -- 
Neural Constituency Parsing; Dependency Parsing: Dependency Relations -- Formalisms -- 
Transition-based and Graph-based Dependency Parsing;


The representation of Meaning: Meaning representation -- Computational
desiderata for representation; Lexical Semantics: word senses --
relations -- WordNet; Word Sense Disambiguation: Dictionary-based --
Supervised -- Minimally-supervised -- Word Similarity: thesaurus
methods -- distributional methods; Discourse Processing: Reference
resolution -- Anaphora resolution algorithms -- Co-reference
resolution

{{{unit}}}
|Unit IV|Natural Language Processing With Python |9| 


{{{unit}}}
|Unit V|Machine Translation, IR And IE|9|
Machine Translation: Problems in machine translation -- Classical MT
-- Statistical MT; Information Retrieval: The vector space model --
Term weighting -- Evaluation of IR; Information Extraction: Named
entity recognition -- Relation detection and classification

\hfill *Total: 45*

** Course Outcomes
After the completion of this course, students will be able to: 
- Describe the language models (K2)
- Explain levels of knowledge in language processing (K2)
- Write Python programs for text processing (K3)
- Apply NLP techniques to MT, IR and IE systems (K3)
 
     
** References
1. Daniel Jurafsky and James H Martin, “Speech and Language Processing: An introduction to Natural Language Processing, Computational Linguistics and Speech Recognition”,2nd Edition, Prentice Hall, 2008.
2. Tanveer Siddiqui, U.S. Tiwary, “Natural Language Processing and Information Retrieval”, Oxford University Press, 2008.
3. Steven Bird, Ewan Klein, and Edward Loper, “Natural Language Processing with Python”, O’Reilly, 2009.
4. Christopher D. Manning, Hinrich Schutze, Foundations of Statistical Natural Language Processing, MIT Press, 1999.
5. Nitin Indurkhya, Fred J. Damerau, Handbook of Natural Language Processing, 2nd Edition, CRC Press, 2010.
