* <<<CP1224>>> NATURAL LANGUAGE PROCESSING
:Properties:
:author:  B Senthil Kumar, D Thenmozhi
:date: 11 May 2022
:end:

#+startup: showall

{{{credits}}}
|L|T|P|C|
|3|0|0|3|

** Course Objectives
- To learn the fundamentals in language processing.
- To understand the language modeling using vector semantics.
- To understand the syntactic parsing in language processing.
- To understand representation of meaning in semantics.

{{{unit}}}
|Unit I |Introduction|6| 
Knowledge in language processing -- Ambiguity; Text Normalization -- N-grams -- Evaluation -- Sampling -- 
Generalization -- Smoothing


{{{unit}}}
|Unit II|Word Level and Syntactic Analysis |6| 
English Word Classes -- Part-of-Speech Tagging; Constituency Grammar: Context-Free Grammar -- 
Grammar rules for Engligh -- Treebanks; Dependency Parsing: Dependency Relations -- Formalisms -- 
Dependency Treebanks;


{{{unit}}}
|Unit III|Lexical and Vector Semantics|6|
Lexical Semantics -- Vector Semantics -- Words and vectors -- Cosine similarity -- TF-IDF -- PPMI -- Word2Vec -- Semantic properties 
of embeddings -- Evaluating vector model; 


{{{unit}}}
|Unit IV|Semantic Analysis|6|
Word Senses: Senses Relations -- WordNet -- Word Sense Disambiguation; Semantic Roles: Diathesis Alternations 
-- Problems -- Proposition Bank -- Semantic Role Labeling


{{{unit}}}
|Unit V|Semantic Analysis|6|
Word Senses: Senses Relations -- WordNet -- Word Sense Disambiguation; Semantic Roles: Diathesis Alternations 
-- Problems -- Proposition Bank -- Semantic Role Labeling


\hfill *Total: 45*

** Course Outcomes
After the completion of this course, students will be able to: 
- Apply the vector semantics in language modeling (K3)
- Apply the syntactic analysis in language processing (K3)
- Explain the meaning representation for natural languages. (K2)
- Apply semantic analysis for words and sentences. (K3)
 
 Suggested Exercise:
 1) Apply Tokenizer, n-grams for text pre-processing.
 2) Apply TF-IDF, Word2Vec vectors for the given text data.
 3) Apply treebanks for context-free and dependency parsing.
 4) Implement Text classification using deep neural networks
 6) Word Similarity
 
     
** References
1. Daniel Jurafsky and James H Martin, “Speech and Language Processing: An introduction to Natural Language Processing, Computational Linguistics and Speech Recognition”,2nd Edition, Prentice Hall, 2008.
2. Tanveer Siddiqui, U.S. Tiwary, “Natural Language Processing and Information Retrieval”, Oxford University Press, 2008.
3. Steven Bird, Ewan Klein, and Edward Loper, “Natural Language Processing with Python”, O’Reilly, 2009.
4. Christopher D. Manning, Hinrich Schutze, Foundations of Statistical Natural Language Processing, MIT Press, 1999.
5. Nitin Indurkhya, Fred J. Damerau, Handbook of Natural Language Processing, 2nd Edition, CRC Press, 2010.
